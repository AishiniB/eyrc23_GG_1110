'''
*****************************************************************************************
*
*        		===============================================
*           		Geo Guide (GG) Theme (eYRC 2023-24)
*        		===============================================
*
*  This file is for documentation of Task 5A of Geo Guide (GG) Theme (eYRC 2023-24).
*
*  This software is made available on an "AS IS WHERE IS BASIS".
*  Licensee/end user indemnifies and will keep e-Yantra indemnified from
*  any and all claim(s) that emanate from the use of the Software or
*  breach of the terms of this agreement.
*
*****************************************************************************************
'''

# Team ID:           GG_1110
# Author List:       Aishini Bhattacharjee, Adithya S Ubaradka, Deepak C Nayak, Upasana Nayak
# Filename:          sample_track.py


******************************************************************************************
Team ID = GG_1110
Trained weights drive link = "https://drive.google.com/drive/folders/1HdPrfJNJyGFt6b7isnr9CwieWOdpZuRW?usp=sharing"

NOTE - While loading the model, load it by using the below lines (path to the whole directory, not the .pb file):
    model = tensorflow.keras.models.load_model('path/to/the/folder/model')
    
*******************************************************************************************
PART 1: Event Identification

    Import Modules:
        The script imports necessary modules, including OpenCV (cv2), NumPy (np), TensorFlow (tf), and standard Python modules (os, json).

    Utility Functions:
        detect_markers: Detects ArUco markers in a given image using OpenCV's ArUco module.
        arena_coordinates: Calculates the coordinates of the arena based on marker corners.
        get_corner_coordinates: Extracts coordinates from marker corners for each marker ID.
        arena_extraction: Extracts the region of interest (arena) from the frame based on marker coordinates.
        frame_capture: Captures a frame from the video feed.
        event_extraction: Extracts events from the arena, denoises, and processes them for further analysis.
        coord_overlap: Checks if two sets of coordinates overlap.
        pixelate_image: Applies pixelation to an image.
        bilateral_denoising: Applies bilateral denoising to an image.
        increase_saturation: Increases the saturation of an image.
        event_label_prediction: Predicts the labels of events using a trained TensorFlow model.
        bounding_box: Draws bounding boxes around detected events on the arena.
        event_mapping: Maps events to their corresponding regions on the arena.
        map_priority_to_events: Maps priority edges to event labels based on certain conditions.
        event_bot_mapping: Maps event labels to their corresponding bot numbers.

    Global Variables:
        arena, present_coordinates, and predicted_labels are declared as global variables to store intermediate results.

    Main Function (task_4a_return):
        Calls return_4a_helper to obtain identified labels for events.
        Displays the identified labels, processes the identified events for priority mapping, and creates a JSON file for further use.
        Displays the arena with bounding boxes around detected events.

    Helper Function (return_4a_helper):
        Uses the loaded TensorFlow model to predict labels for all events and returns identified labels.

    JSON File Creation:
        The script creates two JSON files:
            priority_edge_order.json: Contains the order of priority edges based on identified events.
            bot_stop_numbers.json: Contains the bot stop numbers corresponding to identified events.

    Displaying Results:
        Displays the labeled arena with bounding boxes around detected events.

    Note:

    The script assumes the existence of a trained TensorFlow model for event label prediction.
    Specific conditions and thresholds for event extraction and processing are implemented based on the requirements of the task.
    
********************************************************************************************************************************
PART 2: Shortest Path Planning

a. Classes:

    Node Class:
        Represents a node in the graph.
        Each node has a name and a list of neighbors (other nodes connected to it).

    Edge Class:
        Represents an edge connecting two nodes.
        Stores source (src), destination (dst), weight, and an attribute indicating the presence of an event.

    Graph Class:
        Combines nodes and edges to create a graph.
        Provides methods to add nodes, add edges, delete edges, and get nodes and edges.

b. Graph Initialization:

    A Graph instance is created.
    Nodes (node0 to node11) are instantiated.
    Edges are added to the graph, forming a connected graph with various weights.
    Some edges have an associated event (has_event attribute).

c. Path Finding:

    Dijkstra's algorithm is implemented in the dijkstra function to find the shortest path from a start node to an end node.
    The algorithm considers edge weights and additional costs for specific three-node paths (set_90).
    The find_shortest_path function iterates through a list of priorities, finding the shortest path for each pair of nodes.
    It handles cases where the backward path might be shorter than the forward path and optimizes accordingly.

d. Example Usage:

    An example graph is created, and the neighbors of node "I" are printed.
    Edge attributes (e.g., event presence) are accessed and printed.
    The find_3_node_lists function generates unique three-node permutations for a given node.
    Paths are printed and encoded based on the provided sets (set_90_right and set_90_left).
    The final shortest path is found, and the encoding is saved to a JSON file (encoded_path.json).

2. Communication with ESP32 (communication.py):
a. Libraries and Constants:

    Libraries:
        socket, json, numpy, cv2, cv2.aruco, time, threading, sample_track (assuming it's a custom module).

    Constants:
        IP address (ESP_IP) and port (ESP_PORT) for connecting to the ESP32.
        Coordinates and thresholds for various events (EVENT_E, EVENT_D, EVENT_C, EVENT_B, EVENT_A, BOT).

b. Sending Path to ESP32:

    The script sends the encoded path to the ESP32 using a socket connection.
    The path data is converted to a JSON string and sent to the ESP32.
    The script waits for an acknowledgment from the ESP32.

c. Video Processing:

    The script captures video frames using OpenCV.
    ArUco markers are detected using the aruco module from OpenCV.
    The bot_status function calculates distances between the robot and specific markers, determining the robot's status.

d. Message Sending:

    Messages are sent to the ESP32 based on the calculated robot status.
    A loop continuously captures frames and sends messages to the ESP32.

e. Threading:

    A separate thread (reset_thread) is used to reset acknowledgment status after a delay.
    The acknowledgment status (previous_ack_received) is a shared variable between threads.

f. File Loading:

    The script loads encoded path data and stop numbers from JSON files (encoded_path.json and bot_stop_numbers.json).

***************************************************************************************************************************************
PART 3: Wifi Communication with esp32

    Importing Modules:
        Essential Python modules are imported, including socket for communication, json for handling JSON data, numpy for numerical operations, cv2 for computer vision, aruco for ArUco marker detection, time for time-related functionalities, and threading for multi-threading. Additionally, an IP address (ESP_IP) and port (ESP_PORT) for connecting to an ESP32 are set.

    Event Coordinates and Thresholds:
        Coordinates and thresholds for different events (E, D, C, B, A) are specified. These include marker IDs and distance thresholds for determining specific robot maneuvers.

    Distance Calculation Function:
        Defines a function (calculate_distance) to calculate the distance between two markers based on their IDs and corner coordinates.

    Thread for Resetting Acknowledgment:
        Implements a thread (reset_thread) that resets the acknowledgment status after a delay of 5 seconds.

    Bot Status Calculation Function:
        Defines a function (bot_status) that calculates distances between the robot and specific markers, determining the robot's status based on predefined criteria.

    Loading Path Data from JSON Files:
        Reads encoded path data and bot stop numbers from JSON files.

    Creating a Socket and Sending Path to ESP32:
        Creates a JSON string with the size and data of the encoded path, establishes a socket connection, sends the JSON string to an ESP32, and receives an acknowledgment.

    Video Processing and ArUco Marker Detection:
        Loads a video file and initializes video capture. Defines the ArUco dictionary and parameters for marker detection.

    Main Loop for Processing Frames:
        Enters a main loop for processing video frames. Detects ArUco markers, calculates distances using the bot_status function, and sends messages to the ESP32 based on the calculated robot status.

    Closing the Video Capture and Socket:
        Releases video capture resources and closes the socket connection.

This script integrates various functionalities, including path planning, communication with an ESP32, and robot control based on ArUco marker detection.

*******************************************************************************************************************************************************

PART 4: QGIS tracking

    Import Modules:
        The script imports necessary modules, including OpenCV (cv2), OpenCV's ArUco module (cv2.aruco), NumPy (np), CSV handling (csv), and mathematical operations (math).

    File Paths:
        Two file paths, all_corners and live_location, are defined. They point to CSV files containing information about ArUco markers and live tracking data, respectively.

    CSV Reading and Writing Functions:
        read_csv: Reads the CSV file specified by the input argument and populates the lat_lon dictionary with ArUco marker IDs as keys and corresponding latitude and longitude as values.
        write_csv: Writes the provided location coordinates to a specified CSV file.

    tracker Function:
        Takes an ArUco marker ID and the lat_lon dictionary as input.
        Checks if the given marker ID exists in the dictionary.
        If yes, retrieves the corresponding latitude and longitude and writes them to the live tracking CSV file.

    tracking Function:
        Takes a frame and a flag ret as inputs, which might be related to video capturing.
        Calls read_csv to load the ArUco marker data from the CSV file.
        Uses ArUco markers and their IDs to track their positions in the provided frame.
        Filters out unwanted marker IDs, calculates distances between them, and determines if they are within a threshold distance.
        If a marker is within the threshold, the script calls the tracker function to update the live tracking CSV file.

    Main Section:
        The main section of the script seems to be commented out, including video capturing and display using OpenCV. Uncommenting this section would enable live tracking with a connected camera.

    Note:
     	This script is designed for a specific hardware setup involving ArUco markers. It is part of a larger system for tracking and navigating based on the detected markers within the QGIS environment.
     	
     	
*****************************************************************************************************************************************************************

PART 5: ESP32 


    Wi-Fi Configuration:
        The script includes the necessary libraries (WiFi.h and ArduinoJson.h) and sets up Wi-Fi credentials (ssid and password) for the robot to connect to a specified network. The chosen Wi-Fi port is 8266, and a WiFiServer is initialized on this port.

    Motor Control and Pins:
        Motor control pins are defined for two motors (motor1Pin1, motor1Pin2, enable1Pin, motor2Pin1, motor2Pin2, enable2Pin). These pins are used to control the direction and speed of the robot.

    Infrared (IR) Sensors and Pins:
        IR sensor pins (irSensorPin1 to irSensorPin5) are defined to detect the line on the surface. These sensors help the robot follow the line.

    Buzzer and LED Pins:
        Pins for a buzzer (buzzerPin) and an LED (ledPin) are defined. These are used for signaling and indicating the robot's state.

    PWM Configuration:
        PWM properties (freq, pwmChannel, resolution, dutyCycle) are set to control the speed of the motors using Pulse Width Modulation.

    Intersection Data Handling:
        The script dynamically allocates an array (intersectionActions) to store intersection actions. The array is filled with data received over Wi-Fi. The total number of intersections is stored in TOTAL_INTERSECTIONS.

    Array Data Reception:
        The handleArrayData function reads incoming JSON data from the connected client, parses it, and populates the intersectionActions array. An acknowledgment is sent back to the client.

    Motor Control Functions:
        Functions like stopMotors, turnLeft, turnRight, and moveStraight control the robot's movements based on the detected line and intersection actions.

    Line Following Logic:
        The default_action function interprets sensor readings and determines the robot's actions (e.g., moving straight, turning left, turning right) based on the line following logic.

    Main Loop:
        The loop function continuously calls default_action to keep the robot navigating based on the line and intersection actions.

    Wi-Fi Communication with Server:
        The script checks for client connections, reads incoming data, and responds accordingly. It adjusts the robot's behavior based on received messages and provides acknowledgment to the client.

    Miscellaneous:
        The script includes additional features such as buzzer and LED control, delay adjustments, and specific actions at intersections.



